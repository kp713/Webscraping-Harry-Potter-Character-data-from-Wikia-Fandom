{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Webscraping Harry Potter Character  data from Wikia /Fandom.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJUaDms2GGPuMX14IKkP4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kp713/Webscraping-Harry-Potter-Character-data-from-Wikia-Fandom/blob/main/Webscraping_Harry_Potter_Character_data_from_Wikia_Fandom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "RVS9-5-WaxKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " char_list = pd.read_csv(\"HO_links.csv\")\n",
        " hp = char_list[\"link\"]\n",
        "hp_links =[]\n",
        "for i in range(0,len(hp)):\n",
        "           hp_links.append (\"https://harrypotter.fandom.com/wiki/\" + hp[i])"
      ],
      "metadata": {
        "id": "_H7aIBuka3HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLxcCjH5anrU"
      },
      "outputs": [],
      "source": [
        "def get_character_info(link_to_character_page):\n",
        "   html = requests.get(link_to_character_page).text\n",
        "   soup = BeautifulSoup(html, 'html5lib')\n",
        "   character = {}\n",
        "   try:\n",
        "       character_info = soup.find('aside')\n",
        "       character[\"name\"] = character_info.h2.text.strip()\n",
        "       items = character_info.findAll('div', \"pi-item pi-data pi-item-spacing pi-border-color\")\n",
        "       for item in items:\n",
        "           key = item.find('h3').text\n",
        "           character[key] = item.find('div', \"pi-data-value pi-font\").text\n",
        "   except:\n",
        "       print(\"couldn't scrape: \", link_to_character_page)\n",
        "   return character"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv           \n",
        "if __name__ == \"__main__\":\n",
        "   links_to_characters = hp_links[0:5]\n",
        "   with open('wd_char.csv', 'w', newline='') as csvfile:\n",
        "       fieldnames = ['name',\n",
        " 'Born',\n",
        " 'Died',\n",
        " 'Blood status',\n",
        " 'Marital status',\n",
        " 'Nationality',\n",
        " 'Also known as',\n",
        " 'Signature',\n",
        " 'Species',\n",
        " 'Gender',\n",
        " 'Height',\n",
        " 'Hair colour',\n",
        " 'Eye colour',\n",
        " 'Skin colour',\n",
        " 'Family members',\n",
        " 'Animagus',\n",
        " 'Boggart',\n",
        " 'Wand',\n",
        " 'Patronus',\n",
        " 'House',\n",
        " 'Loyalty','Occupation','Title(s)','Romances','Weight','Feathers'\n",
        "]\n",
        "       writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "       writer.writeheader()\n",
        "       for link in links_to_characters:\n",
        "           char_data = get_character_info(link)\n",
        "           if not char_data: continue\n",
        "           else:\n",
        "               writer.writerow(char_data)\n",
        "                              "
      ],
      "metadata": {
        "id": "7RYWqnO1a-42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}